{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huitingc\\Anaconda3\\envs\\superres\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.input_dir = \"resized_40\"\n",
    "        self.gt_dir = \"original_80\"\n",
    "        input_names = set(os.listdir(self.input_dir))\n",
    "        gt_names = set(os.listdir(self.gt_dir))\n",
    "        assert(input_names == gt_names)\n",
    "        self.image_names = list(input_names)#[:900]\n",
    "        self.images = [self.get(i) for i in tqdm(range(len(self)))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx]\n",
    "\n",
    "    def get(self, idx):\n",
    "        image_name = self.image_names[idx]\n",
    "        image_path = os.path.join(self.input_dir, image_name)\n",
    "        input_image = cv2.imread(image_path)\n",
    "        bicubic_input = np.clip(cv2.resize(input_image, dsize=None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC).astype('float32') / 255.0, 0.0, 1.0)\n",
    "        bicubic_input = np.clip(cv2.cvtColor(bicubic_input, cv2.COLOR_BGR2YCR_CB), 0.0, 1.0)\n",
    "        input_image = input_image.astype('float32') / 255.0\n",
    "        input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2YCR_CB)\n",
    "        gt_image = cv2.imread(os.path.join(self.gt_dir, image_name)).astype('float32') / 255.0\n",
    "        gt_image = cv2.cvtColor(gt_image, cv2.COLOR_BGR2YCR_CB)\n",
    "        input_image = torch.tensor(input_image).permute(2, 0, 1).float().contiguous()\n",
    "        bicubic_input = torch.tensor(bicubic_input).permute(2, 0, 1).float().contiguous()\n",
    "        gt_image = torch.tensor(gt_image).permute(2, 0, 1).float().contiguous()\n",
    "        return input_image, gt_image, image_name, bicubic_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperRes(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_ch = [96, 76, 65, 55, 47, 39, 32]\n",
    "        self.reconstruct_ch = {\"A1\": 64, \"B1\": 32, \"B2\": 32, \"L\": 4}\n",
    "        self.scale_factor = 2\n",
    "        # self.feature_ch = [32, 26, 22, 18, 14, 11, 8]\n",
    "        # self.reconstruct_ch = {\"A1\": 24, \"B1\": 8, \"B2\": 8, \"L\": 4}\n",
    "        conv_cnn0 = nn.Conv2d(1, self.feature_ch[0], kernel_size=3, padding=1, bias=True)\n",
    "        conv_cnn1 = nn.Conv2d(self.feature_ch[0], self.feature_ch[1], kernel_size=3, padding=1, bias=True)\n",
    "        conv_cnn2 = nn.Conv2d(self.feature_ch[1], self.feature_ch[2], kernel_size=3, padding=1, bias=True)\n",
    "        conv_cnn3 = nn.Conv2d(self.feature_ch[2], self.feature_ch[3], kernel_size=3, padding=1, bias=True)\n",
    "        conv_cnn4 = nn.Conv2d(self.feature_ch[3], self.feature_ch[4], kernel_size=3, padding=1, bias=True)\n",
    "        conv_cnn5 = nn.Conv2d(self.feature_ch[4], self.feature_ch[5], kernel_size=3, padding=1, bias=True)\n",
    "        conv_cnn6 = nn.Conv2d(self.feature_ch[5], self.feature_ch[6], kernel_size=3, padding=1, bias=True)\n",
    "        self.cnn0 = nn.Sequential(conv_cnn0, nn.PReLU())\n",
    "        self.cnn1 = nn.Sequential(conv_cnn1, nn.PReLU())\n",
    "        self.cnn2 = nn.Sequential(conv_cnn2, nn.PReLU())\n",
    "        self.cnn3 = nn.Sequential(conv_cnn3, nn.PReLU())\n",
    "        self.cnn4 = nn.Sequential(conv_cnn4, nn.PReLU())\n",
    "        self.cnn5 = nn.Sequential(conv_cnn5, nn.PReLU())\n",
    "        self.cnn6 = nn.Sequential(conv_cnn6, nn.PReLU())\n",
    "        self.concat_ch_1 = sum(self.feature_ch)\n",
    "        cnn_A1 = nn.Conv2d(self.concat_ch_1, self.reconstruct_ch['A1'], kernel_size=1, padding=0, bias=True)\n",
    "        cnn_B1 = nn.Conv2d(self.concat_ch_1, self.reconstruct_ch['B1'], kernel_size=1, padding=0, bias=True)\n",
    "        cnn_B2 = nn.Conv2d(self.reconstruct_ch['B1'], self.reconstruct_ch['B2'], kernel_size=3, padding=1, bias=True)\n",
    "        self.concat_ch_2 = self.reconstruct_ch['A1'] + self.reconstruct_ch['B2']\n",
    "        self.A1 = nn.Sequential(\n",
    "            cnn_A1,\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        self.B = nn.Sequential(\n",
    "            cnn_B1,\n",
    "            nn.PReLU(),\n",
    "            cnn_B2,\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        self.L = nn.Conv2d(self.reconstruct_ch['A1'] + self.reconstruct_ch['B2'], self.scale_factor * self.scale_factor, kernel_size=1, padding=0, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        n, c, h, w = x.shape\n",
    "        assert(1 == c)\n",
    "        scale_factor = (self.scale_factor, self.scale_factor)\n",
    "        bicubic_x = F.interpolate(x, scale_factor=scale_factor, mode='bicubic')\n",
    "        x0 = self.cnn0(x)\n",
    "        x1 = self.cnn1(x0)\n",
    "        x2 = self.cnn2(x1)\n",
    "        x3 = self.cnn3(x2)\n",
    "        x4 = self.cnn4(x3)\n",
    "        x5 = self.cnn5(x4)\n",
    "        x6 = self.cnn6(x5)\n",
    "        feature_concat = torch.cat([x0, x1, x2, x3, x4, x5, x6], dim=1)\n",
    "        a_out = self.A1(feature_concat)\n",
    "        b_out = self.B(feature_concat)\n",
    "        reconstruct_concat = torch.cat([a_out, b_out], dim=1)\n",
    "        output = self.L(reconstruct_concat)\n",
    "        # print(\"c={}\".format(c))\n",
    "        reshape_out = torch.zeros((n, 1, h * self.scale_factor, w * self.scale_factor), device=device)\n",
    "        grid_x, grid_y = torch.meshgrid(torch.arange(0, h * self.scale_factor, self.scale_factor), torch.arange(0, w * self.scale_factor, self.scale_factor), indexing='ij')\n",
    "        # print(\"grid_x={}\".format(grid_x))\n",
    "        # print(\"grid_y={}\".format(grid_y))\n",
    "        reshape_out[:, :, grid_x, grid_y] = output[:, 0:1, :, :].contiguous()\n",
    "        # grid_x, grid_y = torch.meshgrid(torch.arange(0, h * self.scale_factor, self.scale_factor), torch.arange(1, w * self.scale_factor, self.scale_factor), indexing='ij')\n",
    "        reshape_out[:, :, grid_x + 1, grid_y] = output[:, 1:2, :, :].contiguous()\n",
    "        # grid_x, grid_y = torch.meshgrid(torch.arange(1, h * self.scale_factor, self.scale_factor), torch.arange(0, w * self.scale_factor, self.scale_factor), indexing='ij')\n",
    "        reshape_out[:, :, grid_x, grid_y + 1] = output[:, 2:3, :, :].contiguous()\n",
    "        # grid_x, grid_y = torch.meshgrid(torch.arange(1, h * self.scale_factor, self.scale_factor), torch.arange(1, w * self.scale_factor, self.scale_factor), indexing='ij')\n",
    "        reshape_out[:, :, grid_x + 1, grid_y + 1] = output[:, 3:4, :, :].contiguous()\n",
    "        return bicubic_x + reshape_out.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13233/13233 [01:09<00:00, 189.30it/s]\n"
     ]
    }
   ],
   "source": [
    "PT_PATH = \"saved.pt\"\n",
    "train_dataset = CustomImageDataset()\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=0, loss=0.001957472400529497\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=1, loss=0.0014323109304051722\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=2, loss=0.0013831408445878963\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=3, loss=0.001297830517908327\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=4, loss=0.0011968268166264303\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=5, loss=0.0011003735661798725\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=6, loss=0.0010338924642567327\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=7, loss=0.0009806029547745503\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=8, loss=0.0009394141643048476\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=9, loss=0.0009099206090620794\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=10, loss=0.0008921105649685356\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=11, loss=0.0008756404387431952\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=12, loss=0.0008633052237400627\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=13, loss=0.0008553056241747019\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=14, loss=0.0008453231180339884\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=15, loss=0.0008380400654984412\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=16, loss=0.000830436808454664\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=17, loss=0.0008248143216863478\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=18, loss=0.0008180999282848782\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=19, loss=0.0008131334791646147\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=20, loss=0.0008085672985193698\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=21, loss=0.0008045014593500252\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=22, loss=0.0008009118957293077\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=23, loss=0.0007961282066207416\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=24, loss=0.0007925516220591842\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=25, loss=0.000789397847121364\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=26, loss=0.0007860944961292826\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=27, loss=0.0007825894431834751\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=28, loss=0.0007796077828094302\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=29, loss=0.0007767996127550188\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=30, loss=0.0007738005685374599\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=31, loss=0.0007711578438819712\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=32, loss=0.0007685088072208111\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=33, loss=0.0007663006421617673\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=34, loss=0.0007643642454297051\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=35, loss=0.0007626911450585909\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=36, loss=0.0007603685607082777\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=37, loss=0.0007589156787623212\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=38, loss=0.000758046675127012\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=39, loss=0.0007557959588778591\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=40, loss=0.0007530955724413729\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=41, loss=0.0007506613914644673\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=42, loss=0.0007490186138669189\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=43, loss=0.0007475725105292374\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=44, loss=0.0007464161247192988\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=45, loss=0.0007442307573748654\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=46, loss=0.0007420705712944335\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=47, loss=0.0007402015459776696\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=48, loss=0.0007378720464402351\n",
      "one_image.shape=(80, 80, 3)\n",
      "image_path=Barbara_Walters_0003.jpg\n",
      "epoch=49, loss=0.0007359090501179405\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SuperRes().to(device)\n",
    "# if torch.cuda.is_available():\n",
    "    # model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "epochs = 50\n",
    "loss_fn = nn.MSELoss()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    cnt = 0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        input_image, gt_image, image_name, bicubic_input = data\n",
    "        input_image = input_image.to(device)\n",
    "        bicubic_input = bicubic_input.to(device)\n",
    "        gt_image = gt_image.to(device)\n",
    "        # print(\"bicubic_input.shape={}\".format(bicubic_input.shape))\n",
    "        output_y = model(input_image[:, 0:1, :, :]) # only Y-channel\n",
    "        # print(\"output_y.shape={}\".format(output_y.shape))\n",
    "        # print(\"input_image[:, 1:, :, :].shape={}\".format(bicubic_input[:, 1:, :, :].shape))\n",
    "        new_images = torch.concat([output_y, bicubic_input[:, 1:, :, :]], dim=1)\n",
    "        # new_images = torch.concat([bicubic_input[:, :1, :, :], bicubic_input[:, 1:, :, :]], dim=1) # ok\n",
    "        # print(\"new_images.shape={}\".format(new_images.shape))\n",
    "        loss = loss_fn(output_y, gt_image[:, 0:1, :, :])\n",
    "        epoch_loss += float(loss.item()) * input_image.shape[0]\n",
    "        cnt += input_image.shape[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(\"batch={}\".format(i))\n",
    "    epoch_loss /= cnt\n",
    "    one_image = np.clip(new_images[0, :, :, :].cpu().permute(1, 2, 0).detach().numpy(), 0.0, 1.0)\n",
    "    assert not np.any(np.isnan(one_image))\n",
    "    # one_image = bicubic_input[0, :, :, :].cpu().permute(1, 2, 0).detach().numpy() # ok\n",
    "    # cv2.imwrite('debug/one_image_ycc{}.exr'.format(epoch), one_image)\n",
    "    # cv2.imwrite('debug/one_image{}.exr'.format(epoch), cv2.cvtColor(one_image, cv2.COLOR_YCrCb2BGR))\n",
    "    one_image = (cv2.cvtColor(one_image, cv2.COLOR_YCrCb2BGR) * 255.0)#.astype('uint8') # FIX weird dots astype('uint8') can make negative values become a large positive value\n",
    "    print(\"one_image.shape={}\".format(one_image.shape))\n",
    "    print(\"image_path={}\".format(image_name[0]))\n",
    "    debug_out_path = os.path.join(\"debug\", image_name[0])\n",
    "    cv2.imwrite(debug_out_path, one_image)        \n",
    "    print(\"epoch={}, loss={}\".format(epoch, epoch_loss))\n",
    "    if epoch % 10 ==0:\n",
    "        torch.save(model, 'checkpoint.pt')\n",
    "\n",
    "torch.save(model, PT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('superres')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "085b70d4f7cfe15b65e4d755bf59e20d3735d94cd4cf8ce815bf411e5f3cb15f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
